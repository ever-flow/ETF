## 1. 프로젝트 배경 및 목표

### 1.1. 문제 정의: 정보 과잉 시대의 딜레마

최근 몇 년간 ETF(상장지수펀드) 시장은 급격히 성장하며 수많은 상품이 출시되었습니다. 이러한 양적 팽창은 투자자에게 다양한 선택지를 제공했지만, 동시에 **정보 과잉(Information Overload)** 문제를 야기했습니다. 투자자들은 수백 개에 달하는 ETF 중에서 자신의 투자 철학, 목표, 위험 감수 능력에 부합하는 최적의 상품을 선별하는 데 큰 어려움을 겪고 있습니다.

단순히 과거 수익률이나 운용 자산 규모와 같은 단편적인 지표에 의존하는 투자 방식은 개인의 재무 상황이나 심리적 특성을 반영하지 못합니다. 이는 시장 변동 시 **인지 편향(Cognitive Bias)**에 따른 비합리적 의사결정으로 이어져, 결국 불필요한 손실을 초래할 위험이 큽니다.

### 1.2. 프로젝트 목표: 데이터 기반의 합리적 투자 결정 지원

본 프로젝트는 이러한 **'ETF 선택의 난'**을 해결하고자 시작되었습니다. 사용자의 투자 성향을 체계적으로 분석하고, 이를 기반으로 **AI 개인 맞춤형 ETF 추천 및 포트폴리오 시뮬레이션 기능**을 제공하는 것을 핵심 목표로 삼았습니다. 궁극적으로는 투자자가 데이터에 기반한 합리적 의사결정을 내리고, 자신만의 투자 원칙을 세워나갈 수 있도록 돕는 신뢰도 높은 금융 도구를 개발하고자 합니다.

## 2. 시스템 아키텍처 및 UI/UX 설계

### 2.1. 기술 스택 및 아키텍처

본 시스템은 **Streamlit 기반의 멀티 페이지 웹 애플리케이션**으로 개발되었습니다. Streamlit은 Python만으로 신속하게 데이터 기반의 인터랙티브 웹 앱을 구축할 수 있어, 복잡한 프론트엔드 개발 없이 데이터 분석 및 시각화 핵심 로직에 집중할 수 있는 장점이 있어 채택되었습니다.

시스템은 다음과 같은 명확하고 확장 가능한 디렉터리 구조를 갖습니다.

- **`app.py`**: 애플리케이션의 메인 파일이자 진입점입니다. 사이드바에 사용자 프로필과 시스템 정보를 표시하고, 각 페이지로의 접근을 관리하는 관문 역할을 합니다.
- **`pages/`**: 애플리케이션의 핵심 기능 페이지들이 위치하며, 각 파일은 독립적인 모듈로 작동합니다.
    - `1_투자성향설문.py`: 사용자의 투자 성향을 파악합니다.
    - `2_추천결과.py`: AI 알고리즘 기반의 추천 결과를 시각화합니다.
    - `3_상세분석.py`: 선택한 ETF에 대한 심층 분석 데이터를 제공합니다.
    - `4_포트폴리오.py`: 포트폴리오 구성 및 시뮬레이션 기능을 담당합니다.
- **`utils/`**: `etf_recommender.py`와 같이 추천 로직, 데이터 처리, API 연동 등 재사용 가능한 핵심 유틸리티 함수들을 모아 관리하여 코드의 모듈성과 유지보수성을 높였습니다.

### 2.2. UI/UX 설계 원칙

사용자 경험(UX) 설계는 **편의성, 직관성, 명확성**이라는 세 가지 원칙에 초점을 맞췄습니다.

- **일관성**: 모든 페이지에 `st.set_page_config` 설정을 공통으로 적용하여 통일된 제목, 아이콘, 레이아웃을 유지함으로써 사용자가 어떤 페이지에 있더라도 일관된 브랜드 경험을 느끼도록 했습니다.
- **직관성**: 복잡한 금융 지표를 사용자가 쉽게 이해할 수 있도록 재사용 가능한 UI 컴포넌트를 적극 활용했습니다.
    - `display_metric_with_help` 함수는 주요 지표 옆에 물음표 아이콘을 배치하여, 마우스를 올리면 해당 용어의 정의와 의미를 설명하는 툴팁을 제공합니다.
    - `display_etf_card_with_help` 함수는 각 ETF의 핵심 정보를 가독성 높은 카드 형태로 요약하여 사용자가 여러 상품을 한눈에 비교할 수 있도록 돕습니다.
- **명확성**: 사용자가 시스템의 현재 상태와 다음 단계를 명확하게 인지할 수 있도록 시각적 피드백을 강화했습니다. 설문 페이지의 진행률 표시줄, 데이터 로딩 중 스피너 애니메이션, 작업 완료 후 성공/실패 메시지 등이 이에 해당합니다.

## 3. 데이터 파이프라인 및 관리 전략

안정적이고 효율적인 데이터 관리는 시스템의 핵심 기반입니다.

- **데이터 소스**: **FinanceDataReader(FDR)** 라이브러리를 통해 **한국 ETF 45개**와 **미국 ETF 약 80개**의 일별 가격 데이터를 실시간으로 수집합니다. 이를 통해 다양한 시장과 섹터를 포괄하는 폭넓은 분석이 가능합니다.
- **데이터 전처리**: 수집된 원본 데이터(Raw Data)는 결측치 처리, 수익률 계산 등의 전처리 과정을 거쳐 분석에 적합한 형태로 가공됩니다.
- **캐싱 전략**: API 호출 비용을 절감하고 사용자 응답 속도를 극대화하기 위해 **6시간 주기의 캐싱 전략**을 도입했습니다. `fetch_etf_data_with_retry` 함수는 네트워크 오류 발생 시 최대 3회까지 자동으로 재시도하는 로직을 포함하여 데이터 확보의 안정성을 보장합니다.
- **ETF 메타데이터 관리**: 모든 ETF는 기술, 에너지, 헬스케어, 채권 등 주요 섹터 정보와 매핑되어 있습니다. 이는 사용자의 테마 선호도를 추천 알고리즘에 직접 반영하고, 상세 분석 정보를 제공하는 기반이 됩니다.

## 4. AI 추천 알고리즘 심층 분석

본 시스템의 핵심은 협업 필터링과 콘텐츠 기반 필터링을 결합한 **하이브리드 추천 알고리즘**입니다. 이는 `RealETFRecommender` 클래스를 통해 정교하게 구현되었습니다.

### 4.1. 가상 데이터 기반 협업 필터링 (Collaborative Filtering)

- **Cold Start 문제 해결**: 실제 사용자 데이터가 전무한 서비스 초기 단계의 한계를 극복하기 위해, **GPT를 활용하여 200명 규모의 가상 사용자 선호도 데이터(`user_etf_preferences.xlsx`)를 생성**했습니다. 이는 다양한 투자 성향 프로필을 가정하고, 각 프로필이 선호할 만한 ETF에 가상의 평점을 부여하는 방식으로 구성되었습니다.
- **알고리즘 적용**: 이 가상 데이터를 기반으로 **사용자 기반 협업 필터링**을 적용합니다. 즉, 설문에 응답한 사용자와 가장 유사한 투자 성향을 가진 가상 사용자들이 선호했던 ETF를 추천 후보군에 포함시킵니다. 이 점수는 `cf_score`로 산출되며, 개인의 성향과 직접적으로 관련 없는 잠재적 우량 ETF를 발견하게 해줌으로써 추천 결과의 **다양성과 의외성(Serendipity)**을 확보하는 데 기여합니다.

### 4.2. 콘텐츠 기반 필터링 (Content-Based Filtering)

- **고급 위험 지표 계산**: `calculate_risk_metrics` 함수는 ETF의 성과를 다각적으로 평가하기 위해 다음과 같은 고급 위험 조정 지표를 계산합니다.
    - **샤프 지수 (Sharpe Ratio)**: 총 위험 한 단위당 얻는 초과수익률로, 가장 보편적인 성과 지표입니다.
    - **소르티노 지수 (Sortino Ratio)**: 변동성 중 오직 '하락 위험'만을 고려하여, 손실에 민감한 투자자에게 더 적합한 지표입니다.
    - **오메가 지수 (Omega Ratio)**: 목표수익률 달성 확률과 실패 확률의 비율로, 전체 수익 분포를 고려한 종합적인 성과 지표입니다.
    - **칼마 지수 (Calmar Ratio)**: 최대 낙폭 대비 수익률로, 위기 상황에서의 회복력을 평가하는 데 유용합니다.
    - **최대 낙폭 (MDD, Max Drawdown)**: 특정 기간 동안 발생한 최대 손실률로, 투자자가 겪을 수 있는 최악의 시나리오를 보여줍니다.
- **UMAP 기반 최적 클러스터링**: `optimize_clustering` 함수는 ETF 간의 본질적인 유사성을 효과적으로 그룹화합니다.
    1. **차원 축소 (UMAP)**: 위에서 계산된 다차원의 지표들을 **UMAP(Uniform Manifold Approximation and Projection)**을 활용해 2차원으로 압축합니다.
    2. **클러스터링 (K-Means & DBSCAN)**: 압축된 데이터에 K-Means와 DBSCAN 알고리즘을 적용하여 유사한 위험-수익 특성을 가진 ETF 그룹을 형성합니다.
    3. **최적화**: **실루엣 점수(Silhouette Score)**를 기준으로 최적의 클러스터 수를 동적으로 탐색합니다. 이후, 사용자의 투자 성향 설문 결과와 가장 유사한 특성을 가진 클러스터(그룹)를 찾아내고, 해당 그룹에 속한 ETF들에 높은 점수를 부여합니다. 이 결과는 `cb_score`로 산출됩니다.

### 4.3. 하이브리드 추천 점수 산출

최종 추천 점수는 두 필터링 방식의 결과를 경험적으로 결정된 가중치로 합산하여 계산됩니다. 콘텐츠 기반 필터링에 더 높은 가중치를 부여하여 **추천의 정확성과 개인화 수준**을 높이는 데 집중했습니다.

> hybrid_score = (cf_score * 0.4) + (cb_score * 0.6)
> 

## 5. 서비스 흐름 및 페이지별 상세 구현

사용자는 총 4단계의 체계적인 흐름을 통해 개인 맞춤형 추천을 받게 됩니다.

### 5.1. 1단계: 투자 성향 설문 (`pages/1_투자성향설문.py`)

위험 감수도, 투자 기간, 목표 수익률, 선호 시장 및 테마 등 총 7가지 질문을 통해 사용자의 투자 프로필을 구체화합니다. 모든 답변은 Streamlit의 **세션 상태(Session State)**에 안전하게 저장되어 이후 모든 분석 단계에서 일관되게 활용됩니다.

### 5.2. 2단계: 추천 결과 확인 (`pages/2_추천결과.py`)

설문이 완료되면 하이브리드 추천 알고리즘이 실행되어 상위 7개의 ETF를 선별합니다. 각 ETF는 핵심 지표가 요약된 카드로 표시되며, Plotly 기반의 **위험도-수익률 산점도**와 **주요 지표 막대그래프**를 통해 사용자가 추천 근거를 시각적으로 명확하게 이해하고 상품 간 우위를 직관적으로 비교할 수 있도록 돕습니다.

### 5.3. 3단계: 상세 분석 (`pages/3_상세분석.py`)

사용자가 추천된 ETF 중 하나를 선택하면, 해당 ETF에 대한 심층 분석 정보를 제공합니다. 소르티노, 칼마, 오메가 지수 등 고급 위험 지표를 다른 추천 ETF들과 비교하여 보여주고, **위험-수익 매트릭스** 내에서 선택한 ETF의 상대적 위치를 시각적으로 파악할 수 있도록 하여 투자 결정의 마지막 단계를 지원합니다.

### 5.4. 4단계: 포트폴리오 구성 (`pages/4_포트폴리오.py`)

사용자가 하나의 ETF를 **핵심 자산(Core ETF)**으로 선택하면, 시스템은 분산 투자 효과를 극대화하기 위해 해당 ETF와 **상관관계가 낮고 샤프 지수가 높은 보완 ETF(Complementary ETF)**를 자동으로 탐색하여 제안합니다. 이는 상관관계 행렬 분석을 통해 포트폴리오의 전체 변동성을 낮추는 전략에 기반합니다.

## 6. 기대 효과 및 향후 계획

### 6.1. 기대 효과 및 의의

본 프로젝트는 투자자에게 단순히 상품을 나열하는 것을 넘어, **개인의 성향에 맞는 투자 전략을 수립하는 방법론**을 제시한다는 점에서 의의가 있습니다. 데이터 기반의 정량적 분석을 통해 비합리적 판단의 개입을 최소화하고, 장기적으로는 사용자의 **금융 이해력(Financial Literacy) 증진**에 기여할 것으로 기대됩니다.

### 6.2. 향후 확장 계획

향후 다음과 같은 방향으로 시스템을 더욱 고도화할 계획입니다.

- **리밸런싱 자동화**: 시장 상황 변화나 자산 비중 이탈 시, 최적의 포트폴리오 비중을 자동으로 재조정하는 기능을 추가하여 지속적인 포트폴리오 관리를 지원합니다.
- **데이터 확장**: 분석 대상을 개별 주식, 채권, 원자재 등 다양한 자산 클래스로 확대하고, 거시경제 지표(금리, 환율 등)를 분석 모델에 통합합니다.
- **알고리즘 고도화**: **LLM(거대 언어 모델)**을 활용하여 기업 공시자료나 뉴스 기사의 텍스트 데이터를 분석, 정성적인 리스크 요인을 추출하고 이를 추천 알고리즘에 통합하여 추천의 정밀도를 한 단계 높일 것입니다.
